{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fe79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7aee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update the probability of a hypothesis based on new evidence or information. Bayes' theorem is expressed mathematically as:\n",
    "P(A/B) = P(B/A)*P(A)/P(B) where P(A/B) is the conditional probability of event A given event B has occurred., \n",
    "\n",
    "P(B/A)  is the conditional probability of event B given event A has occurred. \n",
    "P(A) and P(B) are the probabilities of events A and B, respectively.\n",
    "\n",
    "In words, Bayes' theorem states that the probability of event A occurring given that event B has occurred is proportional to the probability of event B occurring given that event A has occurred, multiplied by the prior probability of event A, and divided by the prior probability of event B.\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including machine learning, statistics, and Bayesian inference, to update beliefs or predictions based on new evidence or observations. It forms the basis of Bayesian statistics and Bayesian reasoning, allowing for the incorporation of prior knowledge into statistical inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008369",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes' theorem is expressed mathematically as:\n",
    "P(A/B) = P(B/A)*P(A)/P(B) where P(A/B) is the conditional probability of event A given event B has occurred., \n",
    "\n",
    "P(B/A)  is the conditional probability of event B given event A has occurred. \n",
    "P(A) and P(B) are the probabilities of events A and B, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5313c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b10913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Bayes' theorem is used in various fields and applications to update beliefs or make predictions based on new evidence or information. Here are some common ways Bayes' theorem is used in practice:\n",
    "\n",
    "Bayesian Inference: In statistics, Bayes' theorem is used for Bayesian inference, a method of statistical inference in which Bayes' theorem is used to update the probability of a hypothesis based on observed data. It allows for the incorporation of prior knowledge or beliefs into the statistical analysis, leading to more accurate estimates of parameters or predictions.\n",
    "\n",
    "Machine Learning: In machine learning, Bayes' theorem is used in Bayesian methods, such as Bayesian classifiers and Bayesian optimization. Bayesian classifiers, such as Naive Bayes classifiers, use Bayes' theorem to classify data points into different classes based on their features. Bayesian optimization algorithms use Bayes' theorem to optimize hyperparameters of machine learning models by iteratively updating a probability distribution over the hyperparameters based on the performance of the model.\n",
    "\n",
    "Medical Diagnosis: Bayes' theorem is used in medical diagnosis to estimate the probability of a disease given certain symptoms or test results. For example, in a diagnostic test for a disease, Bayes' theorem can be used to update the probability of the disease based on the sensitivity and specificity of the test, as well as the prevalence of the disease in the population.\n",
    "\n",
    "Spam Filtering: In email spam filtering, Bayes' theorem is used in Bayesian spam filters to classify emails as spam or non-spam. The filter calculates the probability that an email is spam given certain features (e.g., words in the email) and updates the probability based on new emails received.\n",
    "\n",
    "Search Engines: Bayes' theorem is used in search engines to rank search results based on their relevance to a user's query. Bayesian ranking algorithms use Bayes' theorem to update the relevance scores of documents based on user feedback and interactions with search results.\n",
    "\n",
    "Overall, Bayes' theorem provides a powerful framework for updating beliefs or making predictions in the presence of uncertainty, and its applications extend to diverse fields such as statistics, machine learning, medicine, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. Conditional probability is a fundamental concept that deals with the probability of an event occurring given that another event has already occurred. Bayes' theorem provides a way to update our beliefs about the probability of an event based on new evidence or information.\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability can be understood as follows:\n",
    "1. Bayes' Theorem: Bayes' theorem states that the conditional probability of event A given event B (denoted as P(A/B)can be calculated using the conditional probability of event B given event A(denoted as P(B/A)), the prior probability of event A (denoted as P(A)),and the prior probability of event B (denoted as P(B)), Mathematically, Bayes' theorem is expressed as: P(A/B) = P(B/A)*P(A)/P(B)\n",
    "1. Conditional Probability: Conditional probability is the probability of event A occurring given that event B has already occurred, and it is denoted as P(A/B). It can be calculated using the joint probability of events A and B (denoted as P(A∩B)) and the probability of event B (denoted as P(B) Mathematically, conditional probability is expressed as:   P(A/B) = P(A∩B)/P(B)                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee17618",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba19c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Choosing the appropriate type of Naive Bayes classifier for a given problem depends on various factors, including the characteristics of the dataset and the assumptions made by each type of Naive Bayes classifier. Here's a brief overview of the three main types of Naive Bayes classifiers and considerations for choosing each one:\n",
    "\n",
    "Gaussian Naive Bayes:\n",
    "\n",
    "Assumes that the features follow a Gaussian (normal) distribution.\n",
    "Suitable for continuous or real-valued features.\n",
    "Works well when the dataset has continuous features and the distribution of features within each class is approximately Gaussian.\n",
    "Not suitable for datasets with categorical or discrete features.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Assumes that the features are multinomially distributed.\n",
    "Suitable for datasets with categorical or count-based features (e.g., word frequencies in text classification).\n",
    "Works well for text classification tasks, such as sentiment analysis or document categorization, where features represent word counts or frequencies.\n",
    "Not suitable for datasets with continuous or real-valued features.\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Assumes that the features are binary (i.e., presence or absence).\n",
    "Suitable for datasets with binary or boolean features, such as presence/absence of certain words in text or binary image features.\n",
    "Works well for text classification tasks when features represent binary indicators of word presence in documents.\n",
    "Can be used when the dataset has binary features, but it may not perform well if the features have more than two categories.\n",
    "Considerations for choosing the type of Naive Bayes classifier include:\n",
    "\n",
    "The nature of the features in the dataset (continuous, categorical, binary).\n",
    "The assumptions made by each type of Naive Bayes classifier and how well they align with the characteristics of the dataset.\n",
    "The specific requirements and constraints of the problem domain, such as interpretability, computational efficiency, and the presence of missing values.\n",
    "In practice, it is often beneficial to try multiple types of Naive Bayes classifiers and evaluate their performance using cross-validation or other validation techniques to determine which one works best for a given problem. Additionally, preprocessing techniques such as feature scaling or transformation may be applied to better align the features with the assumptions of a particular Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da864133",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "To classify the new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we can calculate the conditional probabilities for each class and choose the class with the highest probability.\n",
    "\n",
    "Given the frequency table for each feature value for each class, we can compute the conditional probabilities as follows:\n",
    "    For Class A: P(X1 = 3/A) = 4/13\n",
    "        P(X2 = 4/A)= 3/13\n",
    "        P(A) = 1/2 (equal prior probability for each class)\n",
    "        For Class B:\n",
    "        P(X1 = 3/B) = 1/7\n",
    "        P(X2 = 4/B)= 3/7\n",
    "        P(B) = 1/2  (equal prior probability for each class)\n",
    "Now, we can calculate the likelihood of the new instance belonging to each class using the product of the conditional probabilities and the prior probabilities:\n",
    "For Class A:\n",
    "P(A/X1=3, X2=4)=P(X1=3/A)*P(X2=4/A)*P(A)=4/13*3/13*1/2\n",
    "For Class B:\n",
    "P(B/X1=3, X2=4)=P(X1=3/B)*P(X2=4/B)*P(B)=1/7*3/7*1/2    \n",
    "We then compare these probabilities and classify the new instance into the class with the highest probability.\n",
    "\n",
    "Let's calculate these probabilities: \n",
    "For Class A:\n",
    "P(A/X1=3, X2=4 =4/13*3/13*1/2=12/338\n",
    "P(B/X1=3, X2=4)= 1/7*3/7*1/2 = 3/98\n",
    "Comparing these probabilities, we find that P(A/X1=3, X2=4 >  P(B/X1=3, X2=4)\n",
    "4). Therefore, Naive Bayes would predict the new instance to belong to Class A.                                              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
